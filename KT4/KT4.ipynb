{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Импорты",
   "id": "2b35afe3f1f53b13"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:15.210645Z",
     "start_time": "2024-11-08T11:54:15.005541Z"
    }
   },
   "source": "import pytest",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Вариант 2\n",
    "1. А четное-ли число?"
   ],
   "id": "bdc82e8619778f85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:15.258640Z",
     "start_time": "2024-11-08T11:54:15.241580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%file is_even.py\n",
    "\n",
    "def is_even(number):\n",
    "    if number % 2 == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(is_even(5))"
   ],
   "id": "ab0b3917f5b1d7a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting is_even.py\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:15.460906Z",
     "start_time": "2024-11-08T11:54:15.296715Z"
    }
   },
   "cell_type": "code",
   "source": "!python is_even.py",
   "id": "6bd3133d8a453346",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Тестим проверку четности числа",
   "id": "33ac22807f7a717"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:16.133095Z",
     "start_time": "2024-11-08T11:54:16.119930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%file test_is_even.py\n",
    "from KT4.is_even import is_even\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"number, expected\", [(2, True), (3, False), (4, True)])\n",
    "def test_is_even(number, expected):\n",
    "    assert is_even(number) == expected"
   ],
   "id": "250123a81c68dd17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_is_even.py\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:17.392122Z",
     "start_time": "2024-11-08T11:54:16.187908Z"
    }
   },
   "cell_type": "code",
   "source": "!pytest test_is_even.py",
   "id": "a60c2e19b691da78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.9.7, pytest-8.3.3, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\acva0\\Projects\\PycharmProjects\\Pytesting\\KT4\n",
      "plugins: anyio-4.6.2.post1, cov-5.0.0, sugar-1.0.0\n",
      "collected 3 items\n",
      "\n",
      "test_is_even.py \u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\u001B[32m                                                      [100%]\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m3 passed\u001B[0m\u001B[32m in 0.07s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Считаем площадь прямоугольника",
   "id": "93efa85272741c9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:17.454611Z",
     "start_time": "2024-11-08T11:54:17.431824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%file calculate_area.py\n",
    "\n",
    "def calculate_area(length, width):\n",
    "    return length * width\n",
    "\n",
    "print(calculate_area(4, 2))"
   ],
   "id": "dd41814b45aafdce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting calculate_area.py\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:17.656748Z",
     "start_time": "2024-11-08T11:54:17.498158Z"
    }
   },
   "cell_type": "code",
   "source": "!python calculate_area.py",
   "id": "ebc99cfdd5e3a092",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Тестим подсчет площади прямоугольника ",
   "id": "515090010b2d3c2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:17.704334Z",
     "start_time": "2024-11-08T11:54:17.686747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%file test_calculate_area.py\n",
    "from KT4.calculate_area import calculate_area\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"length, width, expected\", [(2, 4, 8), (5, 3, 15), (15, 10, 150)])\n",
    "def test_calculate_area(length, width, expected):\n",
    "    assert calculate_area(length, width) == expected"
   ],
   "id": "9f976e3968aaaa78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_calculate_area.py\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:18.672287Z",
     "start_time": "2024-11-08T11:54:17.751506Z"
    }
   },
   "cell_type": "code",
   "source": "!pytest test_calculate_area.py",
   "id": "7fe987fe9ff0b3cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.9.7, pytest-8.3.3, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\acva0\\Projects\\PycharmProjects\\Pytesting\\KT4\n",
      "plugins: anyio-4.6.2.post1, cov-5.0.0, sugar-1.0.0\n",
      "collected 3 items\n",
      "\n",
      "test_calculate_area.py \u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\u001B[32m                                               [100%]\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m3 passed\u001B[0m\u001B[32m in 0.08s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Какой это треугольник?",
   "id": "6c086848b71851cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:18.719052Z",
     "start_time": "2024-11-08T11:54:18.708358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%file classify_triangle.py\n",
    "\n",
    "def classify_triangle(a, b, c):\n",
    "    if a + b <= c or a + c <= b or b + c <= a:\n",
    "        return \"Подозрительный какой-то...\"\n",
    "    \n",
    "    if a == b == c:\n",
    "        return \"Равносторонний\"\n",
    "    elif a == b or a == c or b == c:\n",
    "        return \"Равнобедренный\"\n",
    "    else:\n",
    "        return \"Разносторонний\"\n",
    "\n",
    "print(classify_triangle(2, 4, 7))"
   ],
   "id": "c70446d361806184",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting classify_triangle.py\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:18.920624Z",
     "start_time": "2024-11-08T11:54:18.771361Z"
    }
   },
   "cell_type": "code",
   "source": "!python classify_triangle.py",
   "id": "6fbe40a2e6b9a3f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подозрительный какой-то...\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Тестим определение типа треугольника",
   "id": "2822cb0bb3be11e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:18.968322Z",
     "start_time": "2024-11-08T11:54:18.956185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%file test_classify_triangle.py\n",
    "from KT4.classify_triangle import classify_triangle\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"a, b, c, expected\", [(2, 2, 2, \"Равносторонний\"), (5, 5, 6, \"Равнобедренный\"), (4, 5, 6, \"Разносторонний\"), (11, 5, 5, \"Подозрительный какой-то...\")])\n",
    "def test_classify_triangle(a, b, c, expected):\n",
    "    assert classify_triangle(a, b, c) == expected"
   ],
   "id": "825831c49794eff4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_classify_triangle.py\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:54:19.965991Z",
     "start_time": "2024-11-08T11:54:19.023474Z"
    }
   },
   "cell_type": "code",
   "source": "!pytest test_classify_triangle.py",
   "id": "8c5cbcd91c34c30c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.9.7, pytest-8.3.3, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\acva0\\Projects\\PycharmProjects\\Pytesting\\KT4\n",
      "plugins: anyio-4.6.2.post1, cov-5.0.0, sugar-1.0.0\n",
      "collected 4 items\n",
      "\n",
      "test_classify_triangle.py \u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\u001B[32m.\u001B[0m\u001B[32m                                           [100%]\u001B[0m\n",
      "\n",
      "\u001B[32m============================== \u001B[32m\u001B[1m4 passed\u001B[0m\u001B[32m in 0.09s\u001B[0m\u001B[32m ==============================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Тестим апгрейд подсчета среднего",
   "id": "ad77dd6ab115d17d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T13:25:03.893211Z",
     "start_time": "2024-11-08T13:25:03.863727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%file test_upgrade_KT2.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "\n",
    "@pytest.mark.parametrize(\"test1, test2, test3, test4, final, expected\", [(10, 20, 30, 40, 50, 30), (21, 35, 42, 13, 8, 20), (24,68, 39, 81, 97, 60)])\n",
    "def test_upgrade_average_grade(test1, test2, test3, test4, final, expected):\n",
    "    df = pd.DataFrame({'Test1': [test1], 'Test2': [test2], 'Test3': [test3], 'Test4': [test4], 'Final': [final]})\n",
    "    grades = df[['Test1', 'Test2', 'Test3', 'Test4', 'Final']]\n",
    "    average = grades.mean()\n",
    "    assert average.mean() == expected"
   ],
   "id": "a835e93e9e0ae24a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_upgrade_KT2.py\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T13:25:06.385644Z",
     "start_time": "2024-11-08T13:25:04.099971Z"
    }
   },
   "cell_type": "code",
   "source": "!pytest test_upgrade_KT2.py",
   "id": "82f207c0e4d1e589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts =============================\u001B[0m\n",
      "platform win32 -- Python 3.9.7, pytest-8.3.3, pluggy-1.5.0\n",
      "rootdir: C:\\Users\\acva0\\Projects\\PycharmProjects\\Pytesting\\KT4\n",
      "plugins: anyio-4.6.2.post1, cov-5.0.0, sugar-1.0.0\n",
      "collected 3 items\n",
      "\n",
      "test_upgrade_KT2.py \u001B[32m.\u001B[0m\u001B[31mF\u001B[0m\u001B[31mF\u001B[0m\u001B[31m                                                  [100%]\u001B[0m\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "\u001B[31m\u001B[1m________________ test_upgrade_average_grade[21-35-42-13-8-20] _________________\u001B[0m\n",
      "\n",
      "test1 = 21, test2 = 35, test3 = 42, test4 = 13, final = 8, expected = 20\n",
      "\n",
      "    \u001B[0m\u001B[37m@pytest\u001B[39;49;00m.mark.parametrize(\u001B[33m\"\u001B[39;49;00m\u001B[33mtest1, test2, test3, test4, final, expected\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, [(\u001B[94m10\u001B[39;49;00m, \u001B[94m20\u001B[39;49;00m, \u001B[94m30\u001B[39;49;00m, \u001B[94m40\u001B[39;49;00m, \u001B[94m50\u001B[39;49;00m, \u001B[94m30\u001B[39;49;00m), (\u001B[94m21\u001B[39;49;00m, \u001B[94m35\u001B[39;49;00m, \u001B[94m42\u001B[39;49;00m, \u001B[94m13\u001B[39;49;00m, \u001B[94m8\u001B[39;49;00m, \u001B[94m20\u001B[39;49;00m), (\u001B[94m24\u001B[39;49;00m,\u001B[94m68\u001B[39;49;00m, \u001B[94m39\u001B[39;49;00m, \u001B[94m81\u001B[39;49;00m, \u001B[94m97\u001B[39;49;00m, \u001B[94m60\u001B[39;49;00m)])\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92mtest_upgrade_average_grade\u001B[39;49;00m(test1, test2, test3, test4, final, expected):\u001B[90m\u001B[39;49;00m\n",
      "        df = pd.DataFrame({\u001B[33m'\u001B[39;49;00m\u001B[33mTest1\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test1], \u001B[33m'\u001B[39;49;00m\u001B[33mTest2\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test2], \u001B[33m'\u001B[39;49;00m\u001B[33mTest3\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test3], \u001B[33m'\u001B[39;49;00m\u001B[33mTest4\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test4], \u001B[33m'\u001B[39;49;00m\u001B[33mFinal\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [final]})\u001B[90m\u001B[39;49;00m\n",
      "        grades = df[[\u001B[33m'\u001B[39;49;00m\u001B[33mTest1\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mTest2\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mTest3\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mTest4\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mFinal\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m]]\u001B[90m\u001B[39;49;00m\n",
      "        average = grades.mean()\u001B[90m\u001B[39;49;00m\n",
      ">       \u001B[94massert\u001B[39;49;00m average.mean() == expected\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE       assert np.float64(23.8) == 20\u001B[0m\n",
      "\u001B[1m\u001B[31mE        +  where np.float64(23.8) = mean()\u001B[0m\n",
      "\u001B[1m\u001B[31mE        +    where mean = Test1    21.0\\nTest2    35.0\\nTest3    42.0\\nTest4    13.0\\nFinal     8.0\\ndtype: float64.mean\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31mtest_upgrade_KT2.py\u001B[0m:9: AssertionError\n",
      "\u001B[31m\u001B[1m________________ test_upgrade_average_grade[24-68-39-81-97-60] ________________\u001B[0m\n",
      "\n",
      "test1 = 24, test2 = 68, test3 = 39, test4 = 81, final = 97, expected = 60\n",
      "\n",
      "    \u001B[0m\u001B[37m@pytest\u001B[39;49;00m.mark.parametrize(\u001B[33m\"\u001B[39;49;00m\u001B[33mtest1, test2, test3, test4, final, expected\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, [(\u001B[94m10\u001B[39;49;00m, \u001B[94m20\u001B[39;49;00m, \u001B[94m30\u001B[39;49;00m, \u001B[94m40\u001B[39;49;00m, \u001B[94m50\u001B[39;49;00m, \u001B[94m30\u001B[39;49;00m), (\u001B[94m21\u001B[39;49;00m, \u001B[94m35\u001B[39;49;00m, \u001B[94m42\u001B[39;49;00m, \u001B[94m13\u001B[39;49;00m, \u001B[94m8\u001B[39;49;00m, \u001B[94m20\u001B[39;49;00m), (\u001B[94m24\u001B[39;49;00m,\u001B[94m68\u001B[39;49;00m, \u001B[94m39\u001B[39;49;00m, \u001B[94m81\u001B[39;49;00m, \u001B[94m97\u001B[39;49;00m, \u001B[94m60\u001B[39;49;00m)])\u001B[90m\u001B[39;49;00m\n",
      "    \u001B[94mdef\u001B[39;49;00m \u001B[92mtest_upgrade_average_grade\u001B[39;49;00m(test1, test2, test3, test4, final, expected):\u001B[90m\u001B[39;49;00m\n",
      "        df = pd.DataFrame({\u001B[33m'\u001B[39;49;00m\u001B[33mTest1\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test1], \u001B[33m'\u001B[39;49;00m\u001B[33mTest2\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test2], \u001B[33m'\u001B[39;49;00m\u001B[33mTest3\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test3], \u001B[33m'\u001B[39;49;00m\u001B[33mTest4\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [test4], \u001B[33m'\u001B[39;49;00m\u001B[33mFinal\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: [final]})\u001B[90m\u001B[39;49;00m\n",
      "        grades = df[[\u001B[33m'\u001B[39;49;00m\u001B[33mTest1\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mTest2\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mTest3\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mTest4\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mFinal\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m]]\u001B[90m\u001B[39;49;00m\n",
      "        average = grades.mean()\u001B[90m\u001B[39;49;00m\n",
      ">       \u001B[94massert\u001B[39;49;00m average.mean() == expected\u001B[90m\u001B[39;49;00m\n",
      "\u001B[1m\u001B[31mE       assert np.float64(61.8) == 60\u001B[0m\n",
      "\u001B[1m\u001B[31mE        +  where np.float64(61.8) = mean()\u001B[0m\n",
      "\u001B[1m\u001B[31mE        +    where mean = Test1    24.0\\nTest2    68.0\\nTest3    39.0\\nTest4    81.0\\nFinal    97.0\\ndtype: float64.mean\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31mtest_upgrade_KT2.py\u001B[0m:9: AssertionError\n",
      "\u001B[36m\u001B[1m=========================== short test summary info ===========================\u001B[0m\n",
      "\u001B[31mFAILED\u001B[0m test_upgrade_KT2.py::\u001B[1mtest_upgrade_average_grade[21-35-42-13-8-20]\u001B[0m - assert np.float64(23.8) == 20\n",
      "\u001B[31mFAILED\u001B[0m test_upgrade_KT2.py::\u001B[1mtest_upgrade_average_grade[24-68-39-81-97-60]\u001B[0m - assert np.float64(61.8) == 60\n",
      "\u001B[31m========================= \u001B[31m\u001B[1m2 failed\u001B[0m, \u001B[32m1 passed\u001B[0m\u001B[31m in 1.25s\u001B[0m\u001B[31m =========================\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74719e824c4d2003"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
